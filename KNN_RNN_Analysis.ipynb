{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8483f66",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random state for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine_data = load_wine()\n",
    "X = wine_data.data\n",
    "y = wine_data.target\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"Number of samples: {X.shape[0]}\")\n",
    "print(f\"Number of classes: {len(np.unique(y))}\")\n",
    "\n",
    "# Basic data exploration\n",
    "wine_df = pd.DataFrame(X, columns=wine_data.feature_names)\n",
    "wine_df['target'] = y\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "print(f\"Shape: {wine_df.shape}\")\n",
    "print(f\"Features: {list(wine_data.feature_names)}\")\n",
    "print(f\"Target classes: {wine_data.target_names}\")\n",
    "\n",
    "print(\"\\nClass Distribution:\")\n",
    "class_counts = pd.Series(y).value_counts().sort_index()\n",
    "for i, count in enumerate(class_counts):\n",
    "    print(f\"Class {i} ({wine_data.target_names[i]}): {count} samples ({count/len(y)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nFeature Statistics (First 5 features):\")\n",
    "print(wine_df.iloc[:, :5].describe())\n",
    "\n",
    "# Visualize class distribution and feature correlations\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Class distribution plot\n",
    "plt.subplot(1, 2, 1)\n",
    "class_names = [f\"Class {i}\\n({wine_data.target_names[i]})\" for i in range(len(wine_data.target_names))]\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "plt.bar(class_names, class_counts.values, color=colors, alpha=0.8, edgecolor='black')\n",
    "plt.title('Wine Dataset - Class Distribution', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(class_counts.values):\n",
    "    plt.text(i, v + 1, str(v), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Feature correlation heatmap (sample of features)\n",
    "plt.subplot(1, 2, 2)\n",
    "sample_features = wine_df.iloc[:, :8]  # First 8 features for visualization\n",
    "correlation_matrix = sample_features.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, fmt='.2f', cbar_kws={'shrink': 0.8})\n",
    "plt.title('Feature Correlation Matrix\\n(First 8 Features)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Split dataset into 80% training and 20% testing with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]} samples ({X_train.shape[0]/X.shape[0]*100:.1f}%)\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples ({X_test.shape[0]/X.shape[0]*100:.1f}%)\")\n",
    "\n",
    "# Check class distribution in splits\n",
    "print(\"\\nClass distribution in splits:\")\n",
    "train_classes = pd.Series(y_train).value_counts().sort_index()\n",
    "test_classes = pd.Series(y_test).value_counts().sort_index()\n",
    "\n",
    "for i in range(len(wine_data.target_names)):\n",
    "    train_pct = train_classes[i] / len(y_train) * 100\n",
    "    test_pct = test_classes[i] / len(y_test) * 100\n",
    "    print(f\"Class {i}: Train={train_classes[i]} ({train_pct:.1f}%), Test={test_classes[i]} ({test_pct:.1f}%)\")\n",
    "\n",
    "# K-Nearest Neighbors (KNN) Implementation\n",
    "print(\"\\nK-NEAREST NEIGHBORS (KNN) IMPLEMENTATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define k values to test\n",
    "k_values = [1, 5, 11, 15, 21]\n",
    "knn_accuracies = []\n",
    "knn_models = {}\n",
    "\n",
    "print(\"Testing different k values for KNN:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for k in k_values:\n",
    "    # Create and train KNN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    knn_accuracies.append(accuracy)\n",
    "    knn_models[k] = knn\n",
    "    \n",
    "    print(f\"k = {k:2d}: Accuracy = {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nBest KNN performance: k = {k_values[np.argmax(knn_accuracies)]} with accuracy = {max(knn_accuracies):.4f}\")\n",
    "\n",
    "# Detailed analysis for best KNN model\n",
    "best_k = k_values[np.argmax(knn_accuracies)]\n",
    "best_knn = knn_models[best_k]\n",
    "y_pred_best_knn = best_knn.predict(X_test)\n",
    "\n",
    "print(f\"\\nDETAILED ANALYSIS FOR BEST KNN MODEL (k = {best_k})\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_best_knn, \n",
    "                          target_names=wine_data.target_names))\n",
    "\n",
    "# Confusion Matrix for KNN\n",
    "cm_knn = confusion_matrix(y_test, y_pred_best_knn)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm_knn)\n",
    "\n",
    "# Radius Neighbors (RNN) Implementation\n",
    "print(\"\\nRADIUS NEIGHBORS (RNN) IMPLEMENTATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define radius values to test\n",
    "radius_values = [350, 400, 450, 500, 550, 600]\n",
    "rnn_accuracies = []\n",
    "rnn_models = {}\n",
    "\n",
    "print(\"Testing different radius values for RNN:\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for radius in radius_values:\n",
    "    try:\n",
    "        # Create and train RNN classifier\n",
    "        rnn = RadiusNeighborsClassifier(radius=radius)\n",
    "        rnn.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = rnn.predict(X_test)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        rnn_accuracies.append(accuracy)\n",
    "        rnn_models[radius] = rnn\n",
    "        \n",
    "        print(f\"Radius = {radius:3d}: Accuracy = {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Radius = {radius:3d}: Error - {str(e)}\")\n",
    "        rnn_accuracies.append(0.0)  # Add 0 for failed attempts\n",
    "\n",
    "if max(rnn_accuracies) > 0:\n",
    "    best_radius_idx = np.argmax(rnn_accuracies)\n",
    "    best_radius = radius_values[best_radius_idx]\n",
    "    print(f\"\\nBest RNN performance: radius = {best_radius} with accuracy = {max(rnn_accuracies):.4f}\")\n",
    "else:\n",
    "    print(\"\\nAll RNN models failed - radius values may be too large for this dataset\")\n",
    "\n",
    "# Detailed analysis for best RNN model (if successful)\n",
    "if max(rnn_accuracies) > 0:\n",
    "    best_radius = radius_values[np.argmax(rnn_accuracies)]\n",
    "    best_rnn = rnn_models[best_radius]\n",
    "    y_pred_best_rnn = best_rnn.predict(X_test)\n",
    "    \n",
    "    print(f\"\\nDETAILED ANALYSIS FOR BEST RNN MODEL (radius = {best_radius})\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred_best_rnn, \n",
    "                              target_names=wine_data.target_names))\n",
    "    \n",
    "    # Confusion Matrix for RNN\n",
    "    cm_rnn = confusion_matrix(y_test, y_pred_best_rnn)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm_rnn)\n",
    "else:\n",
    "    print(\"\\nCannot provide detailed RNN analysis - all models failed\")\n",
    "    print(\"Suggestion: Try smaller radius values or scale the data\")\n",
    "\n",
    "# Visualization and Comparison\n",
    "print(\"\\nVISUALIZATION AND COMPARISON\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('KNN vs RNN Classification Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: KNN Accuracy Trends\n",
    "axes[0, 0].plot(k_values, knn_accuracies, 'bo-', linewidth=2, markersize=8, \n",
    "                markerfacecolor='lightblue', markeredgecolor='blue')\n",
    "axes[0, 0].set_xlabel('K Value', fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Accuracy', fontweight='bold')\n",
    "axes[0, 0].set_title('KNN: Accuracy vs K Values', fontweight='bold')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].set_ylim([0, 1])\n",
    "\n",
    "# Add value labels\n",
    "for i, (k, acc) in enumerate(zip(k_values, knn_accuracies)):\n",
    "    axes[0, 0].annotate(f'{acc:.3f}', (k, acc), \n",
    "                       textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "# Plot 2: RNN Accuracy Trends\n",
    "if max(rnn_accuracies) > 0:\n",
    "    axes[0, 1].plot(radius_values, rnn_accuracies, 'ro-', linewidth=2, markersize=8,\n",
    "                    markerfacecolor='lightcoral', markeredgecolor='red')\n",
    "    axes[0, 1].set_xlabel('Radius Value', fontweight='bold')\n",
    "    axes[0, 1].set_ylabel('Accuracy', fontweight='bold')\n",
    "    axes[0, 1].set_title('RNN: Accuracy vs Radius Values', fontweight='bold')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].set_ylim([0, 1])\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (r, acc) in enumerate(zip(radius_values, rnn_accuracies)):\n",
    "        if acc > 0:\n",
    "            axes[0, 1].annotate(f'{acc:.3f}', (r, acc), \n",
    "                               textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "else:\n",
    "    axes[0, 1].text(0.5, 0.5, 'RNN Failed\\n(Radius too large)', \n",
    "                   ha='center', va='center', transform=axes[0, 1].transAxes,\n",
    "                   fontsize=14, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightcoral\"))\n",
    "    axes[0, 1].set_title('RNN: Failed Analysis', fontweight='bold')\n",
    "\n",
    "# Plot 3: Comparison Bar Chart\n",
    "models = ['Best KNN', 'Best RNN'] if max(rnn_accuracies) > 0 else ['Best KNN']\n",
    "accuracies = [max(knn_accuracies), max(rnn_accuracies)] if max(rnn_accuracies) > 0 else [max(knn_accuracies)]\n",
    "colors = ['lightblue', 'lightcoral'] if max(rnn_accuracies) > 0 else ['lightblue']\n",
    "\n",
    "bars = axes[1, 0].bar(models, accuracies, color=colors, edgecolor='black', alpha=0.8)\n",
    "axes[1, 0].set_ylabel('Accuracy', fontweight='bold')\n",
    "axes[1, 0].set_title('Model Comparison', fontweight='bold')\n",
    "axes[1, 0].set_ylim([0, 1])\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    axes[1, 0].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                   f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Plot 4: Confusion Matrix for Best Model\n",
    "if max(rnn_accuracies) > 0 and max(rnn_accuracies) > max(knn_accuracies):\n",
    "    cm = cm_rnn\n",
    "    title = f'Best Model Confusion Matrix\\n(RNN, radius={best_radius})'\n",
    "else:\n",
    "    cm = cm_knn\n",
    "    title = f'Best Model Confusion Matrix\\n(KNN, k={best_k})'\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=wine_data.target_names,\n",
    "            yticklabels=wine_data.target_names,\n",
    "            ax=axes[1, 1])\n",
    "axes[1, 1].set_title(title, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Predicted', fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Actual', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Performance summary table\n",
    "print(\"\\nPERFORMANCE SUMMARY TABLE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "summary_data = {\n",
    "    'K/Radius': k_values + radius_values,\n",
    "    'Algorithm': ['KNN'] * len(k_values) + ['RNN'] * len(radius_values),\n",
    "    'Accuracy': knn_accuracies + rnn_accuracies\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df['Accuracy (%)'] = summary_df['Accuracy'] * 100\n",
    "\n",
    "print(summary_df.to_string(index=False, float_format='%.3f'))\n",
    "\n",
    "# Analysis and Interpretation\n",
    "print(\"\\nANALYSIS AND INTERPRETATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nObservations:\")\n",
    "print(f\"• Best KNN model: k = {k_values[np.argmax(knn_accuracies)]} with accuracy = {max(knn_accuracies):.4f}\")\n",
    "\n",
    "if max(rnn_accuracies) > 0:\n",
    "    best_rnn_idx = np.argmax(rnn_accuracies)\n",
    "    print(f\"• Best RNN model: radius = {radius_values[best_rnn_idx]} with accuracy = {max(rnn_accuracies):.4f}\")\n",
    "    \n",
    "    if max(rnn_accuracies) > max(knn_accuracies):\n",
    "        print(\"• RNN outperformed KNN\")\n",
    "    elif max(knn_accuracies) > max(rnn_accuracies):\n",
    "        print(\"• KNN outperformed RNN\")\n",
    "    else:\n",
    "        print(\"• KNN and RNN achieved similar performance\")\n",
    "else:\n",
    "    print(\"• RNN failed with the tested radius values (too large for dataset scale)\")\n",
    "\n",
    "print(f\"\\nOverall Best Model:\")\n",
    "if max(rnn_accuracies) > 0:\n",
    "    if max(rnn_accuracies) > max(knn_accuracies):\n",
    "        best_overall = f\"RNN (radius={radius_values[np.argmax(rnn_accuracies)]})\"\n",
    "        best_acc = max(rnn_accuracies)\n",
    "    else:\n",
    "        best_overall = f\"KNN (k={k_values[np.argmax(knn_accuracies)]})\"\n",
    "        best_acc = max(knn_accuracies)\n",
    "else:\n",
    "    best_overall = f\"KNN (k={k_values[np.argmax(knn_accuracies)]})\"\n",
    "    best_acc = max(knn_accuracies)\n",
    "\n",
    "print(f\"   {best_overall} with accuracy = {best_acc:.4f} ({best_acc*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\n\")\n",
    "print(\"• Small k values in KNN can lead to overfitting (high variance)\")\n",
    "print(\"• Large k values in KNN can lead to underfitting (high bias)\")\n",
    "print(\"• RNN requires careful radius selection based on data scale\")\n",
    "print(\"• Feature scaling might improve RNN performance\")\n",
    "print(\"• Wine dataset has clear class separability, enabling high accuracy\")\n",
    "\n",
    "\n",
    "# Final results summary\n",
    "print(\"\\nCONCLUSION\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"   • Dataset: Wine Dataset ({X.shape[0]} samples, {X.shape[1]} features, 3 classes)\")\n",
    "print(f\"   • Best performing model: {best_overall}\")\n",
    "print(f\"   • Achieved accuracy: {best_acc:.4f} ({best_acc*100:.2f}%)\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
